import os
import time
import sounddevice as sd
import numpy as np
from scipy.io.wavfile import write
from openai import OpenAI
from pydub import AudioSegment
from pydub.playback import play
import io

# [ì£¼ì˜] ë…¸ì¶œëœ API í‚¤ëŠ” ê¼­ ì‚­ì œ(Revoke)í•˜ê³  ìƒˆ í‚¤ë¥¼ ë°œê¸‰ë°›ì•„ ì‚¬ìš©í•˜ì„¸ìš”!
client = OpenAI(api_key="")

# 48000Hzê°€ ë¦¬ëˆ…ìŠ¤ ë‚´ì¥ ë§ˆì´í¬ í‘œì¤€ì…ë‹ˆë‹¤.
FS = 48000  
DURATION = 10  
FILENAME = "input_test.wav"

def record_audio():
    print(f"\nğŸ¤ ë“£ê³  ìˆìŠµë‹ˆë‹¤... (ì§€ê¸ˆ í¬ê²Œ ë§ì”€í•˜ì„¸ìš”!)")
    
    try:
        # device=Noneìœ¼ë¡œ ë‘ë©´ ì•„ê¹Œ ì„¤ì •ì°½ì—ì„œ ì„ íƒí•œ 'ê¸°ë³¸ ë§ˆì´í¬'ë¥¼ ìë™ìœ¼ë¡œ ì”ë‹ˆë‹¤.
        recording = sd.rec(int(DURATION * FS), samplerate=FS, channels=1, dtype='int16', device=None)
        sd.wait()
        
        max_vol = np.abs(recording).max()
        print(f"âœ… ë…¹ìŒ ì™„ë£Œ (ì‹ í˜¸ ê°•ë„: {max_vol})")
        
        if max_vol < 500: # ìµœì†Œ 500~1000ì€ ë„˜ì–´ì•¼ ëª©ì†Œë¦¬ê°€ ë“¤ë¦¬ëŠ” ìƒíƒœì…ë‹ˆë‹¤.
            print("âš ï¸ ì•„ì§ ì†Œë¦¬ê°€ ë„ˆë¬´ ì‘ìŠµë‹ˆë‹¤! ì„¤ì •ì—ì„œ 'Internal Microphone'ì„ ì„ íƒí–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
            
        write(FILENAME, FS, recording)
    except Exception as e:
        print(f"âŒ ë…¹ìŒ ì—ëŸ¬: {e}")

def process_voice_ai():
    try:
        # [Step 1] STT: Whisper í˜¸ì¶œ ì‹œ í•œêµ­ì–´ ì„¤ì •ì„ ê°•ì œí•©ë‹ˆë‹¤.
        with open(FILENAME, "rb") as audio_file:
            transcript = client.audio.transcriptions.create(
                model="whisper-1", 
                file=audio_file,
                language="ko" # í•œêµ­ì–´ ì¸ì‹ë¥  í–¥ìƒ
            )
        user_text = transcript.text
        print(f"ğŸ‘¤ ë‚˜: {user_text}")

        if not user_text.strip() or user_text == ". .":
            print("âš ï¸ ì¸ì‹ì´ ì•ˆ ë˜ì—ˆìŠµë‹ˆë‹¤. ë§ˆì´í¬ ì„¤ì •ì„ ë‹¤ì‹œ í™•ì¸í•´ ì£¼ì„¸ìš”.")
            return

        # [Step 2] GPT-4o ìƒë‹´
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ì¹œì ˆí•œ ì¼€ì´í¬ ê°€ê²Œ ì‚¬ì¥ë‹˜ì…ë‹ˆë‹¤. ë‹¤ì •í•˜ê²Œ 2-3ë¬¸ì¥ìœ¼ë¡œ ë‹µí•˜ì„¸ìš”."},
                {"role": "user", "content": user_text}
            ]
        )
        ai_text = response.choices[0].message.content
        print(f"ğŸ° ì‚¬ì¥ë‹˜: {ai_text}")

        # [Step 3] TTS: ìŒì„± ìƒì„± ë° ì¬ìƒ
        speech_response = client.audio.speech.create(
            model="tts-1",
            voice="nova",
            input=ai_text
        )
        
        audio_data = io.BytesIO(speech_response.content)
        audio_segment = AudioSegment.from_file(audio_data, format="mp3")
        
        print("ğŸ”Š ì‚¬ì¥ë‹˜ ëª©ì†Œë¦¬ ì¬ìƒ ì¤‘...")
        play(audio_segment)

    except Exception as e:
        print(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}")

if __name__ == "__main__":
    print("=== ë“œë””ì–´ ë§ˆì´í¬ ì¡ëŠ” ë‚ ! ì¼€ì´í¬ ìƒë‹´ì› í…ŒìŠ¤íŠ¸ ===")
    while True:
        input("\n[Enter] í‚¤ë¥¼ ëˆ„ë¥´ê³  ë…¹ìŒì„ ì‹œì‘í•˜ì„¸ìš”.")
        record_audio()
        process_voice_ai()